<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="utf-8">
  
  <title>Purumir&#39;s Blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="This blog contains the items about machine learning, sw architect, management and my favorites.">
<meta name="keywords" content="machine learning, sw architecture, management, favorites">
<meta property="og:type" content="website">
<meta property="og:title" content="Purumir&#39;s Blog">
<meta property="og:url" content="https://purumir.github.io/index.html">
<meta property="og:site_name" content="Purumir&#39;s Blog">
<meta property="og:description" content="This blog contains the items about machine learning, sw architect, management and my favorites.">
<meta property="og:locale" content="ko">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Purumir&#39;s Blog">
<meta name="twitter:description" content="This blog contains the items about machine learning, sw architect, management and my favorites.">
  
    <link rel="alternate" href="/atom.xml" title="Purumir&#39;s Blog" type="application/atom+xml">
  
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  

  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap.min.css" integrity="sha384-1q8mTJOASx8j1Au+a5WDVnPi2lkFfwwEAa8hDDdjZlpLegxhjVME1fgjWPGmkzs7" crossorigin="anonymous">

  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css" integrity="sha384-XdYbMnZ/QjLh6iI4ogqCTaIjrFk87ip+ekIjefZch0Y+PvJ8CDYtEs1ipDmPorQ+" crossorigin="anonymous">

  <link rel="stylesheet" href="/css/styles.css">
  

</head>
</html>
<body>
  <nav class="navbar navbar-inverse">
  <div class="container">
    <!-- Brand and toggle get grouped for better mobile display -->
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#main-menu-navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      
    </div>

    <!-- Collect the nav links, forms, and other content for toggling -->
    <div class="collapse navbar-collapse" id="main-menu-navbar">
      <ul class="nav navbar-nav">
        
          <li><a class="active"
                 href="/index.html">Home</a></li>
        
          <li><a class=""
                 href="/archives/">Archives</a></li>
        
      </ul>

      <!--
      <ul class="nav navbar-nav navbar-right">
        
          <li><a href="/atom.xml" title="RSS Feed"><i class="fa fa-rss"></i></a></li>
        
      </ul>
      -->
    </div><!-- /.navbar-collapse -->
  </div><!-- /.container-fluid -->
</nav>

  <div class="container">
    <div class="blog-header">
  <h1 class="blog-title">Purumir&#39;s Blog</h1>
  
    <p class="lead blog-description">Machine Learning, SW architect, Management, favorites</p>
  
</div>

    <div class="row">
        <div class="col-sm-8 blog-main">
          
  
    <article id="post-2021년-서울지하철을-통해-본-사람들의-이동-노선별-일별-요일별-월별-승-하차" class="article article-type-post" itemscope itemprop="blogPost">

  <header class="article-header">
    
  
    <h1 itemprop="name">
      <a class="article-title" href="/2022/01/23/2021년-서울지하철을-통해-본-사람들의-이동-노선별-일별-요일별-월별-승-하차/">2021년 서울지하철을 통해 본 사람들의 이동-(노선별) 일별 승하차</a>
    </h1>
  


  </header>

  <div class="article-meta">
    <div class="article-datetime">
  <a href="/2022/01/23/2021년-서울지하철을-통해-본-사람들의-이동-노선별-일별-요일별-월별-승-하차/" class="article-date"><time datetime="2022-01-23T11:53:14.000Z" itemprop="datePublished">2022-01-23</time></a>
</div>

    
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/data-anlytics/">data anlytics</a> / <a class="article-category-link" href="/categories/data-anlytics/usecases/">usecases</a> / <a class="article-category-link" href="/categories/data-anlytics/usecases/subway-station/">subway station</a>
  </div>


  </div>
  <div class="article-inner">

    <div class="article-entry" itemprop="articleBody">
      
        <script data-ad-client="ca-pub-4548072043503266" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<p><script async src="https://www.googletagmanager.com/gtag/js?id=UA-158998069-1"></script></p>
<p><script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'UA-158998069-1');
</script></p>
<blockquote>
<p><strong>사람들은  수 많은 지하철역중에 어디를 이용할까? (작성중)</strong></p>
</blockquote>
<p>11개월의 데이터( <a href="https://purumir.github.io/2022/01/22/2021년-서울지하철을-통해-본-사람들의-이동/">이전포스팅</a> 에서 이야기 한대로 data.go.kr 에 공개된 데이터가 2021.01~2021.11까지 공개되어 있습니다.) 를 가지고 각 일자별, 요일별, 월별 흐름을 보기로 하였습니다. 1시간마다 기록되어 있는 승/하차 인원중 전체를 살펴보고, 이후 출근 시간(06:00~10:00, 4시간) 과 퇴근시간(05:00~09:00, 4시간)을 중점적으로 살펴보겠습니다.</p>
<p>사용된 툴은 일종의 BI툴이라고 할수 있는 Google Analytics 제품군의 일부인 data studio ( <a href="https://datastudio.google.com/" target="_blank" rel="noopener">https://datastudio.google.com/</a> )와 Google Sheet(데이터셋을 업로드) 사용하였습니다. </p>
<hr>
<h3 id="LINE-호선-별-전체-합계-일별-평균-시간별-평균-승하차"><a href="#LINE-호선-별-전체-합계-일별-평균-시간별-평균-승하차" class="headerlink" title="LINE(호선)별 전체 합계 / 일별 평균 / 시간별 평균 승하차"></a>LINE(호선)별 전체 합계 / 일별 평균 / 시간별 평균 승하차</h3><p>지난 2021년 01월~2021년 11월까지 1호선~9호선(2~3단계)까지 전체 승하차 인원은 24억 1천만명에 달합니다. 1호선과 2호선의 이용객수 차이는 6.14배가 넘습니다. 순환 노선인 2호선이 다른 호선에 비해서 압도적으로 많은 이용객수가 있다고 볼수 있고, 서울을 북동 &lt;-&gt; 서로 가로지르는 7호선(3억 6천 8백만) 과 북서 &lt;-&gt; 동으로 가로지르는 5호선(3억 3천 6백만)이 뒤를 이어 이용객수가 많습니다.</p>
<p>일별 평균을 보면 약 721만명이 지하철을 이용하고 있고, 2호선은 일평균 2백만명이상, 7호선은 110만명, 5호선은 100만명이 일일 평균이용함을 알수 있습니다. 다른 노선들은 일평균 100만명을 하회하고 있습니다.</p>
<p><img src="/images/data_analytics/seoul_subway_station_gettingon_gettingoff_total_20220122.jpg" alt></p>
<p><sup><a href="#fn_" id="reffn_"></a></sup>: 11개월동안 전체 승하차 인원표</p>
<p>승차(승차/환승승차) 와 하차(하차/환승하차)를 각각 분리하여 보면 다음과 같습니다. 승차 인원은 전체 12억 5백9십만정도이고, 하차 인원은 12억 4백6십만 정도입니다.  승차를 했으면 하차를 해야 하는데 이 수치가 130만정도가 차이가 나는데, 이것은 9호선 1~2단계 구간(민자구간)과 중앙선, 분당선, 신분당선등 다른 노선으로 하차한 승객들 때문일 것으로 보입니다. 이 비중은 1%안쪽으로 비중이 크지 않습니다.</p>
<p><img src="/images/data_analytics/seoul_subway_station_gettingon_total_20220122.jpg" alt></p>
<p><sup><a href="#fn_" id="reffn_"></a></sup>: 11개월동안 전체 승차인원표</p>
<p><img src="/images/data_analytics/seoul_subway_station_gettingoff_total_20220122.jpg" alt></p>
<p><sup><a href="#fn_" id="reffn_"></a></sup>: 11개월동안 전체 하차 인원표</p>
<hr>
<h3 id="날짜-date-로-본-출퇴근-시간-승하차-패턴"><a href="#날짜-date-로-본-출퇴근-시간-승하차-패턴" class="headerlink" title="날짜(date)로 본 출퇴근 시간 승하차 패턴"></a>날짜(date)로 본 출퇴근 시간 승하차 패턴</h3><p><img src="/images/data_analytics/seoul_subway_station_gettingon_gettingoff_date_0607_20220122.jpg" alt></p>
<p><sup><a href="#fn_" id="reffn_"></a></sup>: 일자별(date)로 본 06~07시 승하차 노선별 현황</p>
<p><img src="/images/data_analytics/seoul_subway_station_gettingon_gettingoff_date_0708_20220122.jpg" alt></p>
<p><sup><a href="#fn_" id="reffn_"></a></sup>: 일자별(date)로 본 07~08시 승하차 노선별 현황</p>
<p><img src="/images/data_analytics/seoul_subway_station_gettingon_gettingoff_date_0809_20220122.jpg" alt></p>
<p><sup><a href="#fn_" id="reffn_"></a></sup>: 일자별(date)로 본 08~09시 승하차 노선별 현황</p>
<p><img src="/images/data_analytics/seoul_subway_station_gettingon_gettingoff_date_0910_20220122.jpg" alt></p>
<p><sup><a href="#fn_" id="reffn_"></a></sup>: 일자별(date)로 본 09~10시 승하차 노선별 현황</p>
<p>위 그래프에서 약 4시간(06:00~10:00) 출근 시간동안 비슷한 패턴을 보이는데 2-&gt;7-&gt;5-&gt;3-&gt;4-&gt;6-&gt;8-&gt;1-&gt;9 호선 같은 순서로 사람들이 승하차를 많이 함을 알수 있습니다.  앞선 포스팅에서 이야기 하였듯이 9호선은 2~3단계 노선의 승하차 인원만 존재하여 가장 순위가 낮지만 실제로는 상위순위일 것으로 예상됩니다.</p>
<p>위 그래프에서 출근시간대에 <strong><em>7월~8월 중순까지 그래프가 움푹 파인 구간</em></strong>이 있는데 이 구간은 여름휴가 기간동안 승하차 인원이 감소하는 것으로 생각할 수 있습니다.</p>
<hr>
<p><strong>11개월 구간 출퇴근 시간 전체 승하차 인원</strong></p>
<p>아래표는 11개월동안 출근 시간 구간의 승하차 인원의 전체 합계입니다.</p>
<p><img src="/images/data_analytics/seoul_subway_station_gettingon_gettingoff_morning_20220122.jpg" alt></p>
<p><sup><a href="#fn_" id="reffn_"></a></sup>: 오전 출근시간동안 승하차 인원표</p>
<p>약 4시간에 달하는 출근 시간동안 전체 승하차인원(24억 1천만)의 약 27%가 집중되고 있습니다.  08:00~09:00시간대에 승하차인원(2억 6천 2백만, 11%)이 가장 많음을 알수 있습니다. 09:00~10:00까지도 이러한 경향은 계속된다고 볼수 있습니다.</p>
<p>아래표는 11개월동안 퇴근 시간 구간의 승하차 인원의 전체 합계입니다.</p>
<p><img src="/images/data_analytics/seoul_subway_station_gettingon_gettingoff_afternoon_20220122.jpg" alt></p>
<p><sup><a href="#fn_" id="reffn_"></a></sup>: 오후 퇴근시간동안 승하차 인원표</p>
<p>약 4시간에 달하는 퇴근 시간동안 전체 승하차인원(24억 1천만)의 약 30%가 집중되고 있습니다. 18:00~19:00시간대에 승하차 인원(2억 6천 1백만, 11%)이 집중되고 있습니다. 19:00~20:00 보다 17:00~18:00의 수치가 더 높아 이때 퇴근이 더 많을 것이라고 예상할 수 있습니다.</p>
<p>위 표들은 승하차인원의 합계이기 때문에, 이를 상세화 하면 다음과 같이 승하차를 구분지어 생각할 수 있습니다.</p>
<ul>
<li>아침 출근 시간대<ul>
<li>승차 : 거주지 근처 역에서 승차 , 버스에서 내린 후 지하철에 승차하는 경우</li>
<li>하차 : 주로 일을 하게 되는 사무실 주변역</li>
</ul>
</li>
<li>저녁 퇴근 시간대<ul>
<li>승차 : 주로 일을 하게 되는 사무실 주변역</li>
<li>하차 : 거주지 근처역에서 하차 , 버스를 타기 위해 지하철에서 하차 하는 경우</li>
</ul>
</li>
</ul>

      
    </div>

    
      

    

    <footer class="article-footer">
      <a data-url="https://purumir.github.io/2022/01/23/2021년-서울지하철을-통해-본-사람들의-이동-노선별-일별-요일별-월별-승-하차/" data-id="ckyyjgaqn0000isv0qjokzqlr" class="article-share-link">
        <i class="fa fa-share"></i> Share
      </a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/gettinf-off/">gettinf off</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/getting-on/">getting on</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/movement-pattern/">movement pattern</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/subway-station/">subway station</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/승차/">승차</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/일별/">일별</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/지하철/">지하철</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/하차/">하차</a></li></ul>


    </footer>
  </div>
  
</article>



  
    <article id="post-2021년-서울지하철을-통해-본-사람들의-이동" class="article article-type-post" itemscope itemprop="blogPost">

  <header class="article-header">
    
  
    <h1 itemprop="name">
      <a class="article-title" href="/2022/01/22/2021년-서울지하철을-통해-본-사람들의-이동/">2021년 서울지하철을 통해 본 사람들의 이동- 목표 그리고 데이터셋</a>
    </h1>
  


  </header>

  <div class="article-meta">
    <div class="article-datetime">
  <a href="/2022/01/22/2021년-서울지하철을-통해-본-사람들의-이동/" class="article-date"><time datetime="2022-01-22T13:28:24.000Z" itemprop="datePublished">2022-01-22</time></a>
</div>

    
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/data-anlytics/">data anlytics</a> / <a class="article-category-link" href="/categories/data-anlytics/usecases/">usecases</a> / <a class="article-category-link" href="/categories/data-anlytics/usecases/subway-station/">subway station</a>
  </div>


  </div>
  <div class="article-inner">

    <div class="article-entry" itemprop="articleBody">
      
        <script data-ad-client="ca-pub-4548072043503266" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<p><script async src="https://www.googletagmanager.com/gtag/js?id=UA-158998069-1"></script></p>
<p><script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'UA-158998069-1');
</script></p>
<blockquote>
<p><strong>우리는 언제(When) 어디(Where) 를 통해 어디(Where)로 이동하는가</strong></p>
</blockquote>
<p>2021년 한해동안 사람들은 어떤 식으로 움직였을지에 대해서 분석할수 없을까라는 생각을 하게 되었습니다. 우리는 도보, 자전거등 개인이동수단(비동력), 자동차(자가용, 택시, 공유 차량), 버스, 지하철, 비행기등의 수단을 통해 이곳에서 저곳으로 다시 저곳에서 또 다른 곳으로 계속적인 이동을 합니다. </p>
<p>하지만 경제 생활 인구의 대부분은 아침에 직장이 위치하는 곳으로 이동하고, 저녁에는 다시 집으로 돌아오는 반복적인 패턴을 보일 것입니다. </p>
<p>이러한 여러가지 이동 수단중 가장 많은 비중을 차지할 것으로 예상되는 서울지하철을 통해서 사람들이 어떻게 이동하는지 이동 패턴이 궁금해졌습니다.  이를 위해 공공 데이터 포털( <a href="https://data.go.kr" target="_blank" rel="noopener">https://data.go.kr</a> )에 공개된 데이터를 찾아보았고, 1~9호선의 승하차 데이터를 찾을수 있었습니다.</p>
<p>사용된 데이터셋은 다음과 같습니다. 두 데이터셋이 거의 포맷이 유사하여, 약간의 정제를 통해 데이터셋을 하나로 병합하였습니다. 아쉬운 점은 공개된 데이터셋이 11월 데이터까지만을 포함하여 12월 패턴을 볼수 없다는 점입니다.</p>
<ul>
<li><p><strong>서울 교통공사_역별 일별 시간대별 승하차인원 정보</strong> </p>
<ul>
<li>데이터 구간 : 2021-01~2021-11</li>
<li><a href="https://www.data.go.kr/data/15048032/fileData.do" target="_blank" rel="noopener">데이터셋 바로가기(data.go.kr)</a></li>
</ul>
</li>
<li><p><strong>서울교통공사_9호선2_3단계 역별일별시간대별승하차인원</strong></p>
<ul>
<li>데이터 구간 : 2021-01~2021-11</li>
<li><a href="https://www.data.go.kr/data/15060424/fileData.do" target="_blank" rel="noopener">데이터셋 바로가기(data.go.kr)</a></li>
</ul>
</li>
</ul>
<p>데이터셋 형태는 아래와 같이 일자, 지하철호선번호 , 지하철역번호 , 지하철역명 , 승차 혹은 하차 / 9호선은 일부 환승승차/환승 하차가 포함된 형태로 구성되어 있습니다. 시간은 06시 이전, 06시~24시까지 1시간 단위로 승하차 인원 수치가 기록되어 있습니다.</p>
<p><img src="/images/data_analytics/seoul_subway_station_gettingon_gettingoff_dataset_20220122.jpg" alt></p>
<p>이번 조사를 통해서 9호선이 민자 구간이 있다는 것은 익히 알고 있었지만, 2~3단계(언주역~종합운동장역/2단계, 종합운동장역~중앙보훈병원역/3단계)는 공공이 참여하여 서울 교통공사가 운영한다는 사실을 알 수 있었습니다. 이 구간의 데이터는 공공 데이터 포탈에 공개가 되어 있습니다.</p>
<p><strong>- 다음 포스팅에 이어집니다. -</strong> </p>

      
    </div>

    
      

    

    <footer class="article-footer">
      <a data-url="https://purumir.github.io/2022/01/22/2021년-서울지하철을-통해-본-사람들의-이동/" data-id="ckyyjgaqw0001isv0l2f8o86i" class="article-share-link">
        <i class="fa fa-share"></i> Share
      </a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/gettinf-off/">gettinf off</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/getting-on/">getting on</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/movement-pattern/">movement pattern</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/subway-station/">subway station</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/승차/">승차</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/지하철/">지하철</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/하차/">하차</a></li></ul>


    </footer>
  </div>
  
</article>



  
    <article id="post-airflow-hdfs-sensor" class="article article-type-post" itemscope itemprop="blogPost">

  <header class="article-header">
    
  
    <h1 itemprop="name">
      <a class="article-title" href="/2021/10/15/airflow-hdfs-sensor/">airflow hdfs sensor 설정과 사용법</a>
    </h1>
  


  </header>

  <div class="article-meta">
    <div class="article-datetime">
  <a href="/2021/10/15/airflow-hdfs-sensor/" class="article-date"><time datetime="2021-10-15T07:37:31.000Z" itemprop="datePublished">2021-10-15</time></a>
</div>

    
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/data-analytics/">data analytics</a> / <a class="article-category-link" href="/categories/data-analytics/ETL/">ETL</a>
  </div>


  </div>
  <div class="article-inner">

    <div class="article-entry" itemprop="articleBody">
      
        <p>airflow에는 HDFS상에서 파일의 존재유무를 체크하는(poke)하는 hdfs_sensor라는 기능이 있습니다.</p>
<p><br></p>
<p><strong>hdfs sensor를 위한 필요 패키지 설치</strong></p>
<ul>
<li>pip install apache-airflow-providers-apache-hdfs</li>
<li>pip install snakebite-py3</li>
</ul>
<p><br></p>
<p><strong>hdfs sensor 사용을 위한 connection 정보 설정</strong></p>
<ul>
<li>airflow &gt; Admin &gt; Connections 에서 hdfs sensor에서 접근할 hdfs 정보를 입력<ul>
<li>hdfs_connection / IP / Port 정보</li>
<li>HDFS Name Node 정보를 입력 (IP, Port 8020)</li>
</ul>
</li>
</ul>
<p><br></p>
<p><strong>코드에서 HdfsSensor 모듈 import를 통한 sensor 기능 사용</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> airflow.providers.apache.hdfs.sensors.hdfs <span class="keyword">import</span> HdfsSensor</span><br><span class="line"></span><br><span class="line">hdfs_sensor = HdfsSensor(</span><br><span class="line">    task_id = <span class="string">"hdfs_path_sensor"</span>,</span><br><span class="line">    filepath = <span class="string">"모니터링 하고자 하는 파일의 full path(파일명포함)"</span>,</span><br><span class="line">    hdfs_conn_id = <span class="string">"hdfs_connection"</span>, <span class="comment"># airflow &gt; Admin &gt; Connections 에 설정한 hdfs connection 명</span></span><br><span class="line">    queue =<span class="string">"queue"</span>, <span class="comment"># airflow사용 queue,</span></span><br><span class="line">    poke_interval=<span class="number">30</span>, <span class="comment"># 지정한 interval이 지난후 체크</span></span><br><span class="line">    timeout=<span class="number">11400</span>, <span class="comment"># 지정한 timeout 시간동안 체크를 지속</span></span><br><span class="line">    dag=dag</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p><br></p>
<p>아래 그림과 같이 Task간에 선행 작업에서 필수적인 파일을 생성했는지 여부를 체크하여, 후행 작업의 시작을 파일이 생성될때까지 순연시키는 효과를 거둘수 있습니다.</p>
<p><img src="/images/sw/airflow_hdfs_sensor_usecase_20211115.JPG" alt></p>
<script data-ad-client="ca-pub-4548072043503266" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>



<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-158998069-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'UA-158998069-1');
</script>


      
    </div>

    
      

    

    <footer class="article-footer">
      <a data-url="https://purumir.github.io/2021/10/15/airflow-hdfs-sensor/" data-id="ckyyjgark000disv0xw1138sw" class="article-share-link">
        <i class="fa fa-share"></i> Share
      </a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/airflow/">airflow</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/hdfs/">hdfs</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/hdfssensor/">hdfssensor</a></li></ul>


    </footer>
  </div>
  
</article>



  
    <article id="post-ResNet" class="article article-type-post" itemscope itemprop="blogPost">

  <header class="article-header">
    
  
    <h1 itemprop="name">
      <a class="article-title" href="/2021/03/30/ResNet/">ResNet</a>
    </h1>
  


  </header>

  <div class="article-meta">
    <div class="article-datetime">
  <a href="/2021/03/30/ResNet/" class="article-date"><time datetime="2021-03-29T15:29:22.000Z" itemprop="datePublished">2021-03-30</time></a>
</div>

    
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/machine-learning/">machine learning</a> / <a class="article-category-link" href="/categories/machine-learning/computer-vision/">computer vision</a>
  </div>


  </div>
  <div class="article-inner">

    <div class="article-entry" itemprop="articleBody">
      
        <p>Deep Network는 Low/Mid/High level features를 추출하여 이를 통해 여러가지 작업을 수행한다. network depth는 이 경우 중요한 요소가 되는데 network가 깊어 질수록 degradation problem이 발생한다.</p>
<blockquote>
<p>with the network depth increasing, accuracy gets saturated (which might be uprising) and then degrades rapidly.</p>
<p>[출처] “Deep Residual Learning for Image Recognition”</p>
</blockquote>
<p>위 정의와 같이 network depth가 증가할 수록 accuracy가 일정 수준까지 증가후 급격히 감소하는 현상이 발생하게 된다.    </p>
<p>network depth가 높으면 train error, test error가 모두 높은 현상이 발생하게 된다. 이는 deeper network를 통해 얻고자 하는 목적과 배치되게 된다.</p>
<p>ResNet은 이 degradation problem을 deep residual learning framework를 통해서 해결하고자 한다.  Residual Network는 plan network를 기반으로 shortcut connections를 추가한것이다.</p>
<p><img src="/images/machine_learning/resnet_building_block_v20210330.jpg" alt></p>
<blockquote>
<p>[출처] “Deep Residual Learning for Image Recognition”</p>
</blockquote>
<p>위 stacked nonlinear layers에 의한 매핑을 H(x)라고 하면, 다른 stacked nonlinear layers mapping을 F(x):=H(x)-x라 할수 있다. 즉. H(x)=F(x)+x로 표현이 가능하다.  이를 통해 H(x) 대신에 Residual Function인 F(x)를 알아냄으로서 문제를 해결할수 있다. 이것이 Residual Learning의 개념이다. </p>
<hr>
<p><strong><em>[Identity Mapping by Shortcuts]</em></strong></p>
<p> input, output의 dimension이 동일한 identity mapping의 경우 위 그림을 수식으로 좀 더 구체적으로 표현하면 다음과 같다.</p>
<script type="math/tex; mode=display">
y=F(x, \{W_{i}\})+x\\
\text{x,y는 input과 output이며}, F(x,{W_{i}})\text{는 학습될 residual mapping의미}</script><p>위와 같은 identity mapping의 경우 추가적인 parameter 혹은 computational complexity를 유발하지 않는다. 학습에 있어서도 SGD with backpropagation을 통해서 학습이 가능하다.</p>
<p>Residual Net은 깊이가 증가함에 따라 accuracy도 같이 증가하여 기존의 network들보다 깊이가 깊어져도 성능저하를 예방할수 있다.</p>
<p>이 논문에서는 plain network와 residual  network간 parameter, depth, width and computational cost가 같으므로 상대적인 성능을 비교할수 있어 이를 비교하고 있다.</p>
<p><strong><em>[Projection Mapping by Shortcuts]</em></strong></p>
<p>input, output의 dimension이 다른 경우는 다음과 같이 linear projection을 통해 연산을 한다.</p>
<script type="math/tex; mode=display">
y=F(x, \{W_{i}\})+W_{s}x</script><p>{작성중}</p>
<hr>
<script data-ad-client="ca-pub-4548072043503266" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-158998069-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'UA-158998069-1');
</script>


      
    </div>

    
      

    

    <footer class="article-footer">
      <a data-url="https://purumir.github.io/2021/03/30/ResNet/" data-id="ckyyjgari000aisv08s499wc1" class="article-share-link">
        <i class="fa fa-share"></i> Share
      </a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/cnn/">cnn</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/computer-vision/">computer vision</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/convolutional-neural-network/">convolutional neural network</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/machine-learning/">machine learning</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/resnet/">resnet</a></li></ul>


    </footer>
  </div>
  
</article>



  
    <article id="post-kubernetes로-spark-submit하기-spark-submit-to-kubernetes" class="article article-type-post" itemscope itemprop="blogPost">

  <header class="article-header">
    
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/05/21/kubernetes로-spark-submit하기-spark-submit-to-kubernetes/">kubernetes로 spark-submit하기(spark-submit to kubernetes)</a>
    </h1>
  


  </header>

  <div class="article-meta">
    <div class="article-datetime">
  <a href="/2020/05/21/kubernetes로-spark-submit하기-spark-submit-to-kubernetes/" class="article-date"><time datetime="2020-05-21T05:09:05.000Z" itemprop="datePublished">2020-05-21</time></a>
</div>

    
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/data-analytics/">data analytics</a> / <a class="article-category-link" href="/categories/data-analytics/spark/">spark</a> / <a class="article-category-link" href="/categories/data-analytics/spark/timeseries/">timeseries</a>
  </div>


  </div>
  <div class="article-inner">

    <div class="article-entry" itemprop="articleBody">
      
        <p>spark 공식 사이트( <a href="https://spark.apache.org/docs/latest/running-on-kubernetes.html" target="_blank" rel="noopener">https://spark.apache.org/docs/latest/running-on-kubernetes.html</a> ) 에 spark-submit을 kubernetes상에서 수행하는 방법에 대해서 나와 있습니다. 가이드에 따라서 container를 빌드하고 이를 이용해 spark-submit을 하는 상황입니다. 이 작업의 컨셉 다이어 그램은 아래와 같습니다.</p>
<p><img src="/images/machine_learning/spark_submit_concept_diagram_v20200521.png" alt></p>
<hr>
<p>제가 겪은 상황은 spark-submit을 kubernetes cluster상에 namespace를 생성하고, 해당 namespace에 istio-injection:enabled를 했을 경우 겪게 되었던 “Initial Job has not accepted any resources: check your cluster UI to ensure that workers are registered and have sufficient resources”에 대한 트러블 슈팅에 대한 내용입니다. 특히 kubeflow를 설치시 istio관련 많은 컴포넌트들이 설치되는데 이로 인해서 위와 같은 에러 상황을 마주하게 되었습니다.</p>
<p>해결책은 spark-submit시 istio-injection을 false처리하는 것입니다. 이를 통해서 spark-submit시 (특히 client mode시) spark driver와 spark executor의 communication이 되지 않아 발생하는 “Initial Job has not accepted any resources: check your cluster UI to ensure that workers are registered and have sufficient resources” 의 트러블 슈팅이 가능합니다.</p>
<p>kubernetes에서 spark-submit을 수행하기 위해서는 다음과 같은 절차를 따릅니다.</p>
<p>1) Namespace 생성 &amp; Service Account 생성 &amp; ClusterRoleBinding 수행</p>
<ul>
<li>Namespace 생성 &amp; istio-injection enable</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubectl create namespace data-platform</span><br><span class="line">kubectl label namespace data-platform istio-injection=enabled</span><br></pre></td></tr></table></figure>
<ul>
<li>Service Account &amp; ClusterRoleBinding 생성</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Using kubectl)</span><br><span class="line">kubectl create serviceaccount spark --namespace=data-platform</span><br><span class="line">kubectl create clusterrolebinding spark-role --clusterrole=edit  --serviceaccount=data-platform:spark --namespace=data-platform</span><br></pre></td></tr></table></figure>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">spark</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">data-platform</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterRoleBinding</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">spark-role</span> </span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">data-platform</span></span><br><span class="line"><span class="attr">roleRef:</span></span><br><span class="line"><span class="attr">  apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br><span class="line"><span class="attr">  kind:</span> <span class="string">ClusterRole</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">edit</span>  </span><br><span class="line"><span class="attr">subjects:</span></span><br><span class="line"><span class="attr">- kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">spark</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">data-platform</span></span><br></pre></td></tr></table></figure>
<p>2) spark-submit시 “—conf spark.kubernetes.executor.annotation.sidecar.istio.io/inject=false” 옵션을 추가하는데, 이는 istio환경에서 POD를 구동시 istio가 side-car를 injection하면서 kubernetes cluster 외부에 있는 spark driver와 kubernetes cluster내부에 있는 spark client의 communication을 blocking하기 때문에 side-car injection을 하지 않게 하는 것입니다.</p>
<p>   “—conf spark.kubernetes.authenticate.oauthTokenFile=<file location>“과 “—conf spark.kubernetes.authenticate.caCertFile=<file location>“은 위에서 생성한 service account의 secret에 있는 token값과 ca.crt내용입니다.</file></file></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">./bin/spark-submit \</span><br><span class="line">--master  k8s://https://&lt;k8s master IP&gt;:6443 \</span><br><span class="line">--deploy-mode client \</span><br><span class="line">--name spark-pi \</span><br><span class="line">--class org.apache.spark.examples.SparkPi \</span><br><span class="line">--conf spark.kubernetes.namespace=data-platform \</span><br><span class="line">--conf spark.kubernetes.authenticate.driver.serviceAccountName=spark \</span><br><span class="line">--conf spark.kubernetes.container.image=&lt;spark official site 가이드 따라 빌드한 컨테이너 이미지&gt; \</span><br><span class="line">--conf spark.kubernetes.driver.volumes.persistentVolumeClaim.&lt;Persistent Volume Claim Name&gt;.options.claimName=&lt;Persistent Volume Claim Name&gt; \</span><br><span class="line">--conf spark.kubernetes.driver.volumes.persistentVolumeClaim.&lt;Persistent Volume Claim Name&gt;.mount.path=&lt;storage class path&gt; \</span><br><span class="line">--conf spark.kubernetes.driver.volumes.persistentVolumeClaim.&lt;Persistent Volume Claim Name&gt;.mount.readOnly=<span class="literal">false</span> \</span><br><span class="line">--conf spark.kubernetes.authenticate.oauthTokenFile=&lt;file location&gt; <span class="comment"># service account(spark) token file</span></span><br><span class="line">--conf spark.kubernetes.authenticate.caCertFile=&lt;file location&gt; <span class="comment"># service account(spark) ca.crt파일</span></span><br><span class="line">--conf spark.kubernetes.executor.request.cores=500m \</span><br><span class="line">--conf spark.kubernetes.driverEnv.memory=1g \</span><br><span class="line">--conf spark.kubernetes.executor.annotation.sidecar.istio.io/inject=<span class="literal">false</span> \ <span class="comment">#istio 환경에서 Initial Job Resource 부족 에러를 해결하기 위한 방법(driver-executor의 통신을 가능하게 함.)</span></span><br><span class="line">--conf spark.executor.cores=1 \</span><br><span class="line">--conf spark.executor.memory=700m \</span><br><span class="line">--conf spark.worker.cores=1 \</span><br><span class="line">--conf spark.driver.host=&lt;이 spark-submit실행 host ip address&gt; \</span><br><span class="line">--conf spark.driver.port=7077 \</span><br><span class="line">--jars elasticsearch-hadoop-7.6.1.jar \</span><br><span class="line">--driver-memory 1g \</span><br><span class="line">--packages org.apache.spark:spark-streaming-kafka-0-8-assembly_2.11:2.4.5 \</span><br><span class="line">/Users/hikari/hanwharnd/ai_platform/spark-2.4.5-bin-hadoop2.7/examples/jars/spark-examples_2.11-2.4.5.jar</span><br></pre></td></tr></table></figure>
<p>위와 같은 command를 수행시 아래 처럼 해당 namespace(data-platform)에서 spark용 Pod가 생성되는 것을 확인할 수 있습니다. 아래의 Pod는 spark-submit을 중지하면 expire됩니다.</p>
<p><img src="/images/machine_learning/spark_submit_to_kubernets_dashboard_v20200521.png" alt></p>
<script data-ad-client="ca-pub-4548072043503266" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-158998069-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'UA-158998069-1');
</script>


      
    </div>

    
      

    

    <footer class="article-footer">
      <a data-url="https://purumir.github.io/2020/05/21/kubernetes로-spark-submit하기-spark-submit-to-kubernetes/" data-id="ckyyjgarx000lisv0cpnwaoya" class="article-share-link">
        <i class="fa fa-share"></i> Share
      </a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/data-analytics/">data analytics</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/elasticsearch/">elasticsearch</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/istio/">istio</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/kafka/">kafka</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/kubernetes/">kubernetes</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/spark/">spark</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/sparkstreaming/">sparkstreaming</a></li></ul>


    </footer>
  </div>
  
</article>



  
    <article id="post-Kafka와-SparkStreaming을-통한-시계열-데이터-저장" class="article article-type-post" itemscope itemprop="blogPost">

  <header class="article-header">
    
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/05/14/Kafka와-SparkStreaming을-통한-시계열-데이터-저장/">Kafka와 SparkStreaming을 통한 시계열 데이터 저장(on kubernetes)</a>
    </h1>
  


  </header>

  <div class="article-meta">
    <div class="article-datetime">
  <a href="/2020/05/14/Kafka와-SparkStreaming을-통한-시계열-데이터-저장/" class="article-date"><time datetime="2020-05-13T23:29:09.000Z" itemprop="datePublished">2020-05-14</time></a>
</div>

    
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/data-analytics/">data analytics</a> / <a class="article-category-link" href="/categories/data-analytics/timeseries/">timeseries</a>
  </div>


  </div>
  <div class="article-inner">

    <div class="article-entry" itemprop="articleBody">
      
        <p>다음과 같은 상황에서 시계열 데이터를 저장하는 과정을 기술하고자 합니다. 3개 지역의 온도 데이터를 kafka를 통해 수집하고, spark streaming으로 처리한후 이를 elasticsearch에 저장하는 과정입니다. 데이터의 수집 현황을 kibana를 통해서 실시간 모니터링합니다.</p>
<p><img src="/images/machine_learning/timeseries_concept_image_v20200514.png" alt></p>
<hr>
<p><strong>아키텍처 설명)</strong></p>
<p>복잡한 처리를 중간에 하지는 않고 수집된 데이터를 바로 저장하는 단순한 패턴입니다.  추후 spark를 통한 시계열 분석은 진행할 예정입니다. 다만 Spark, ElasticSearch는 kubernetes상에서 배포합니다. Kafka는 istio환경에서 helm chart(<a href="https://github.com/helm/charts/tree/master/incubator/kafka" target="_blank" rel="noopener">https://github.com/helm/charts/tree/master/incubator/kafka</a>) 를 이용해 배포시 kafka Pod가 zookeeper Pod (zookeeper-headless.es.svc.cluster.local로 access가 안됨) 에 access하지 못하는 현상이 있어 kafka는 kubernetes외부에 deploy한다는 가정입니다. 따라서, 아키텍처 컨셉은 다음과 같습니다.</p>
<p><img src="/images/machine_learning/spark_submit_from_outside_concept_architecture_v20200529.png" alt></p>
<p>Spark Client Mode로 Spark Job Submit을 kubernetes API Server를 통해서 수행하게 됩니다. 이를 위한 serviceaccount/clusterrolebinding 내용은 다음 글을 참조하시기 바랍니다. (<a href="https://purumir.github.io/2020/05/21/kubernetes로-spark-submit하기-spark-submit-to-kubernetes/">https://purumir.github.io/2020/05/21/kubernetes로-spark-submit하기-spark-submit-to-kubernetes/</a>)</p>
<p>spark submit을 하기 위한 python 코드는 다음과 같습니다. 기본 내용은 kafka에 저장된 데이터를 DStream을 통해서 각 row를 추출하며 이를 ECS(Elastic Common Schema)로 formatting하여 저장하는 것입니다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br></pre></td><td class="code"><pre><span class="line">temperature.py</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkContext</span><br><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkConf</span><br><span class="line"><span class="keyword">from</span> pyspark.streaming <span class="keyword">import</span> StreamingContext</span><br><span class="line"><span class="keyword">from</span> pyspark.streaming.kafka <span class="keyword">import</span> KafkaUtils</span><br><span class="line"><span class="comment">############################################################</span></span><br><span class="line"><span class="comment">#                spark configuration of spark              #</span></span><br><span class="line"><span class="comment">############################################################</span></span><br><span class="line"><span class="comment"># If there is already spark running, you sould use getOrCreate() method.</span></span><br><span class="line">sc = SparkContext().getOrCreate()</span><br><span class="line">sc.setLogLevel(<span class="string">"DEBUG"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># batch interval 1 second</span></span><br><span class="line">ssc = StreamingContext(sc, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">kafkaStream = KafkaUtils.createStream(ssc, <span class="string">'&lt;kafka host ip/kubernetes outside&gt;:2181'</span>, <span class="string">'spark-streaming'</span>, &#123;<span class="string">'temperatureTopic'</span>:<span class="number">1</span>&#125;)</span><br><span class="line"></span><br><span class="line">lines = kafkaStream.map(<span class="keyword">lambda</span> x: x[<span class="number">1</span>])</span><br><span class="line">lines.pprint()</span><br><span class="line"></span><br><span class="line"><span class="comment">############################################################</span></span><br><span class="line"><span class="comment">#            code here elastic json format with ECS        #</span></span><br><span class="line"><span class="comment">############################################################</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">process_streaming</span><span class="params">(series_data)</span>:</span></span><br><span class="line">    <span class="keyword">import</span> datetime</span><br><span class="line">    <span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line">    <span class="comment"># \ 오류 처리</span></span><br><span class="line">    series_data = series_data.replace(<span class="string">"\""</span>, <span class="string">""</span>)</span><br><span class="line">    series_data = series_data.replace(<span class="string">"\'"</span>, <span class="string">"\""</span>)</span><br><span class="line">    </span><br><span class="line">    series_data_json = json.loads(series_data)</span><br><span class="line">    date_time_obj = datetime.datetime.strptime(series_data_json.get(<span class="string">"Record time"</span>), <span class="string">"%Y-%m-%d %H:%M:%S.%f"</span>)</span><br><span class="line">    </span><br><span class="line">    region = series_data_json.get(<span class="string">"Region"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> region == <span class="string">'Seoul'</span>:</span><br><span class="line">        region_temperature_degress = &#123;</span><br><span class="line">            <span class="string">'seoul'</span> : &#123;</span><br><span class="line">              <span class="string">'temperature'</span> : str(series_data_json.get(<span class="string">"Temperature"</span>))</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        hostname = <span class="string">'sensor_seoul_01'</span></span><br><span class="line">        id = <span class="string">'sensor_seoul_01'</span></span><br><span class="line">    <span class="keyword">elif</span> region == <span class="string">'Busan'</span>:</span><br><span class="line">        region_temperature_degress = &#123;</span><br><span class="line">            <span class="string">'busan'</span> : &#123;</span><br><span class="line">              <span class="string">'temperature'</span> : str(series_data_json.get(<span class="string">"Temperature"</span>))</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        hostname = <span class="string">'sensor_busan_01'</span></span><br><span class="line">        id = <span class="string">'sensor_busan_01'</span></span><br><span class="line">    <span class="keyword">elif</span> region == <span class="string">'Jeju'</span>:</span><br><span class="line">        region_temperature_degress = &#123;</span><br><span class="line">            <span class="string">'jeju'</span> : &#123;</span><br><span class="line">              <span class="string">'temperature'</span> : str(series_data_json.get(<span class="string">"Temperature"</span>))</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        hostname = <span class="string">'sensor_jeju_01'</span>    </span><br><span class="line">        id = <span class="string">'sensor_jeju_01'</span></span><br><span class="line"></span><br><span class="line">    elastic_data_json_with_ecs =&#123;</span><br><span class="line">        <span class="string">'@timestamp'</span> : date_time_obj.strftime(<span class="string">"%Y-%m-%dT%H:%M:%S.%f"</span>),</span><br><span class="line">        <span class="string">'ecs'</span> : &#123;</span><br><span class="line">          <span class="string">'version'</span> : <span class="string">'1.0.0'</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="string">'host'</span> : &#123;</span><br><span class="line">          <span class="string">'name'</span> : <span class="string">'sensor'</span>,</span><br><span class="line">          <span class="string">'hostname'</span> : hostname,</span><br><span class="line">          <span class="string">'id'</span> : id</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="string">'event'</span> : &#123;</span><br><span class="line">          <span class="string">'dataset'</span> : <span class="string">'thermometer.air_temperature'</span>,</span><br><span class="line">          <span class="string">'module'</span> : <span class="string">'thermometer'</span>,</span><br><span class="line">          <span class="string">'duration'</span> : <span class="number">10</span>,</span><br><span class="line">          <span class="string">'original'</span>: series_data</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="string">'metricset'</span> : &#123;</span><br><span class="line">          <span class="string">'name'</span> : <span class="string">'air_temperature'</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="string">'service'</span> : &#123;</span><br><span class="line">          <span class="string">'type'</span> : <span class="string">'thermometer'</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="string">'thermometer'</span> : &#123;</span><br><span class="line">          <span class="string">'air_temperature'</span> : </span><br><span class="line">            region_temperature_degress</span><br><span class="line">          </span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> json.dumps(elastic_data_json_with_ecs)</span><br><span class="line"></span><br><span class="line"><span class="comment"># lines map 처리, 개별 timeseries데이터의 row를 elasticsearch에 적재</span></span><br><span class="line"><span class="comment"># ECS(Elastic Common Schema)로 formatting하여 저장함.</span></span><br><span class="line">lines = lines.map(<span class="keyword">lambda</span> item: process_streaming(item)).map(<span class="keyword">lambda</span> x: (<span class="string">'key'</span>, x))</span><br><span class="line">lines.pprint()</span><br><span class="line"></span><br><span class="line"><span class="comment"># RDD마다 elastic search 저장을 위한 function(saveAsNewAPIHadoopFile)를 호출합니다.</span></span><br><span class="line">lines.foreachRDD(<span class="keyword">lambda</span> rdd: rdd.saveAsNewAPIHadoopFile( \</span><br><span class="line">    path=<span class="string">'-'</span>, \</span><br><span class="line">    outputFormatClass=<span class="string">"org.elasticsearch.hadoop.mr.EsOutputFormat"</span>, \</span><br><span class="line">    keyClass=<span class="string">"org.apache.hadoop.io.NullWritable"</span>, \</span><br><span class="line">    valueClass=<span class="string">"org.elasticsearch.hadoop.mr.LinkedMapWritable"</span>, \</span><br><span class="line">    conf=&#123;<span class="string">"es.nodes"</span> : <span class="string">"&lt;elastic search IP&gt;"</span>, <span class="string">"es.port"</span> : <span class="string">"9200"</span>, <span class="string">"es.resource"</span> : <span class="string">"testindex"</span>, <span class="string">"es.input.json"</span>: <span class="string">"yes"</span> &#125;))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ssc.start()</span><br><span class="line">ssc.awaitTermination()</span><br></pre></td></tr></table></figure>
<p>Spark Job sumit 수행을 위한 command는 다음과 같습니다.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">./bin/spark-submit \</span><br><span class="line">--master  k8s://https://&lt;k8s master server ip&gt;:6443 \</span><br><span class="line">--deploy-mode client \</span><br><span class="line">--name spark-pi \</span><br><span class="line">--class org.apache.spark.examples.SparkPi \</span><br><span class="line">--conf spark.kubernetes.namespace=&lt;Spark Pod가 생성되는 kubernetes namespace&gt; \</span><br><span class="line">--conf spark.kubernetes.authenticate.driver.serviceAccountName=&lt;kubernetes service account&gt; \</span><br><span class="line">--conf spark.kubernetes.container.image=&lt;spark 사이트 가이드 따라 빌드한 컨테이너 이미지&gt; \</span><br><span class="line">--conf spark.kubernetes.driver.volumes.persistentVolumeClaim.nfs-pvc-spark-master.options.claimName=nfs-pvc-spark-master \</span><br><span class="line">--conf spark.kubernetes.driver.volumes.persistentVolumeClaim.nfs-pvc-spark-master.mount.path=&lt;NFS Mount Path&gt; \</span><br><span class="line">--conf spark.kubernetes.driver.volumes.persistentVolumeClaim.nfs-pvc-spark-master.mount.readOnly=<span class="literal">false</span> \</span><br><span class="line">--conf spark.kubernetes.authenticate.oauthTokenFile=&lt;Kubernetes Service Account oauth token file&gt; \</span><br><span class="line">--conf spark.kubernetes.authenticate.caCertFile=&lt;Kubernetes Service Account ca crt file&gt; \</span><br><span class="line">--conf spark.kubernetes.executor.request.cores=500m \</span><br><span class="line">--conf spark.kubernetes.driverEnv.memory=1g \</span><br><span class="line">--conf spark.kubernetes.executor.annotation.sidecar.istio.io/inject=<span class="literal">false</span> \ <span class="comment"># side-car injection disable</span></span><br><span class="line">--conf spark.executor.cores=1 \</span><br><span class="line">--conf spark.executor.memory=700m \</span><br><span class="line">--conf spark.worker.cores=1 \</span><br><span class="line">--conf spark.driver.host=&lt;spark job을 submit 하는 host ip&gt; \</span><br><span class="line">--conf spark.driver.port=7077 \</span><br><span class="line">--jars elasticsearch-hadoop-7.6.1.jar \</span><br><span class="line">--driver-memory 1g \</span><br><span class="line">--packages org.apache.spark:spark-streaming-kafka-0-8-assembly_2.11:2.4.5 \</span><br><span class="line">temperature.py</span><br></pre></td></tr></table></figure>
<script data-ad-client="ca-pub-4548072043503266" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-158998069-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'UA-158998069-1');
</script>
      
    </div>

    
      

    

    <footer class="article-footer">
      <a data-url="https://purumir.github.io/2020/05/14/Kafka와-SparkStreaming을-통한-시계열-데이터-저장/" data-id="ckyyjgara0006isv03l6dhvkz" class="article-share-link">
        <i class="fa fa-share"></i> Share
      </a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/data-analytics/">data analytics</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/elasticsearch/">elasticsearch</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/kafka/">kafka</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/kibana/">kibana</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/sparkstreaming/">sparkstreaming</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/timeseries/">timeseries</a></li></ul>


    </footer>
  </div>
  
</article>



  
    <article id="post-오픈-소스-ETL-툴-비교-Apache-NiFi-vs-StreamSets" class="article article-type-post" itemscope itemprop="blogPost">

  <header class="article-header">
    
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/02/06/오픈-소스-ETL-툴-비교-Apache-NiFi-vs-StreamSets/">오픈 소스 ETL 툴 비교(Apache NiFi vs StreamSets)</a>
    </h1>
  


  </header>

  <div class="article-meta">
    <div class="article-datetime">
  <a href="/2020/02/06/오픈-소스-ETL-툴-비교-Apache-NiFi-vs-StreamSets/" class="article-date"><time datetime="2020-02-06T06:32:43.000Z" itemprop="datePublished">2020-02-06</time></a>
</div>

    
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/data-analytics/">data analytics</a> / <a class="article-category-link" href="/categories/data-analytics/ETL/">ETL</a>
  </div>


  </div>
  <div class="article-inner">

    <div class="article-entry" itemprop="articleBody">
      
        <p>빅데이터, AI 시대에 데이터가 존재하는 origin으로부터 데이터를 가져오고 이를 처리후 적재하기 위한 ETL(Extract-Transformation-Load) Tools가 존재합니다.  대표적인 것이 Apache NiFi, Apache Airflow, StreamSets등이 존재합니다.<br></p>
<p>과거 분석을 위해서는 BI(Business Intelligence)와 이를 위한 저장소로 DW(DataWare House)가 사용되었습니다. 최근에는 이러한 아키텍처 보다는 데이터 orgin으로부터 데이터를 수집해 저장하고, R이나 머신러닝/딥러닝등을 이용한 Analyze가 주류를 이루고 있습니다.<br></p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">구분</th>
<th style="text-align:center">설명</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Past</td>
<td style="text-align:center">Apps/RDBMS(계정계)-&gt; ETL -&gt; DW(Data WareHouse) -&gt; ETL -&gt; BI(Business Intelligence)(정보계)</td>
</tr>
<tr>
<td style="text-align:center">Emerging<br>(Current)</td>
<td style="text-align:center">Data Sources(Log/Device/Streams/Apps) -&gt; Ingest -&gt; Data Stores -&gt; Analyze -&gt; Data Consumers(R/ML, Search, BI, Apps)</td>
</tr>
</tbody>
</table>
</div>
<p><br></p>
<p>이 글에서는 Apache NiFi와 StreamSets를 비교해 보고자 합니다.</p>
<div class="table-container">
<table>
<thead>
<tr>
<th></th>
<th>Apache NiFi</th>
<th>StreamSets Data Collector (SDC)</th>
</tr>
</thead>
<tbody>
<tr>
<td>SW개발처</td>
<td>- donation : NSA (2014)<br>- current : Hortonworks</td>
<td>- California 기반의 startup(2014)<br> - open source ETL project</td>
</tr>
<tr>
<td>URLs</td>
<td><a href="https://nifi.apache.org/" target="_blank" rel="noopener">https://nifi.apache.org/</a></td>
<td><a href="https://github.com/streamsets/datacollector" target="_blank" rel="noopener">https://github.com/streamsets/datacollector</a></td>
</tr>
<tr>
<td>개발에 사용된 Language</td>
<td>Java</td>
<td>Java</td>
</tr>
<tr>
<td>License</td>
<td>Apache 2.0 license</td>
<td>Apache 2.0 license</td>
</tr>
<tr>
<td>Usages</td>
<td>Stream Data 혹은 Regular Periodic Batches를 위한 Long Running Job용도</td>
<td>Stream Data 혹은 Regular Periodic Batches를 위한 Long Running Job용도</td>
</tr>
<tr>
<td>데이터</td>
<td>FlowFile(original data + meta-information)</td>
<td>record format<br> (데이터를 규격화된 포맷으로 변환 처리)</td>
</tr>
<tr>
<td>origin type</td>
<td>CSV, Other Record-Based Data 등</td>
<td>CSV, Other Record-Based Data 등</td>
</tr>
<tr>
<td>Components</td>
<td>[Data Provenance] <br>- dataflow내에서 거의 모든 것을 기록하는 Big Brother service <br>- dataflow 수행 history 기록 <br><br>[Controller Service]<br>-processor를 위한 유용한 정보를 제공<br>- SSL certificates, JDBC 설정등,<br>  schema definition <br>- 동일 configuration의 동시 설정을 지원<br><br>[Process Groups] (이것 자체가 dataflows가 됨) <br>- 개별 dataflow를 Process Group으로 묶는 것이 가능<br><br> [Processor Outputs] <br>- Original : FlowFile의 origin <br>- Failure : FlowFile이 처리 오류 발생시 <br>- Success : FlowFilw이 정상적으로 처리시</td>
<td>[Origins] <br>- 데이터가 존재하는 external sources. <br>- dataflow내에서 한개의 origin만이 존재가능<br><br>[Processors]  <br>- data transformers. <br><br>[Destinations] <br>- 데이터 저장 stores<br><br>[Executors] <br>- 다른 processor들에 의해 생성된 event처리 <br> - Email처리 시 Error발생시 이를 처리 → EMail Executor</td>
</tr>
<tr>
<td>특징</td>
<td>- Processor간에 Queue가 존재하여 Flow Control <br>- 핸들링 하는 데이터 포맷에 맞춰 다른 버전의 Processor를 가져야 함.(CSV, XLS별도식)</td>
<td>- Processor간에 Queue가 존재하지 않음 <br>- binary file을 processing가능함 <br>- kakfa conumer가 processor에 binary를 그대로 전송 가능함</td>
</tr>
<tr>
<td>장단점</td>
<td>장점)<br> - dataflow programming concept을 효율적 구현<br>- binary data 처리 가능<br>Data Provenance <br>단점) <br>-Spartan User Interface <br>-record단위 모니터링, 디버깅, 통계 제공 안함.</td>
<td>장점)<br>- record단위 모니터링, 디버깅, 통계 제공<br>- record단위 data와 streaming을 위한 갈끔한 UI <br><br>단점)<br>- 단일 processor 수정을 위해 전체 dataflow의 stop필요<br>- No reusable configuration for processors</td>
</tr>
</tbody>
</table>
</div>
<p>위 비교표에서 볼수 있듯이 큰 차이점은 StreamSets의 경우 한개의 processor의 configuration을 수정하기 위해 전체 dataflow를 정지시켜야 합니다. UI상 Stop버튼을 눌러야 수정을 할 수 있도록 구성 되어 있습니다. </p>
<p>StreamSets의 경우 Startup에서 지속적으로 관리하는 형태라 UI의 구성 자체가 NiFi대비 우수하다고 볼 수 있습니다.  또한, 설치도 docker 형태를 제공하고 있어 편리하게 구성후 테스트를 진행 할 수 있습니다.</p>
<script data-ad-client="ca-pub-4548072043503266" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- Global site tag (gtag.js) - Google Analytics -->

<script async src="https://www.googletagmanager.com/gtag/js?id=UA-158998069-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'UA-158998069-1');
</script>
      
    </div>

    
      

    

    <footer class="article-footer">
      <a data-url="https://purumir.github.io/2020/02/06/오픈-소스-ETL-툴-비교-Apache-NiFi-vs-StreamSets/" data-id="ckyyjgas1000qisv07n5n83pl" class="article-share-link">
        <i class="fa fa-share"></i> Share
      </a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Apache-NiFi/">Apache NiFi</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/ETL/">ETL</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/StreamSets/">StreamSets</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/business-intelligence/">business intelligence</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/machine-learning/">machine learning</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/workflow/">workflow</a></li></ul>


    </footer>
  </div>
  
</article>



  
    <article id="post-dark-knowledge-machine-learning-architecture" class="article article-type-post" itemscope itemprop="blogPost">

  <header class="article-header">
    
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/01/28/dark-knowledge-machine-learning-architecture/">Dark Knowledge (Knowledge Distillation)</a>
    </h1>
  


  </header>

  <div class="article-meta">
    <div class="article-datetime">
  <a href="/2020/01/28/dark-knowledge-machine-learning-architecture/" class="article-date"><time datetime="2020-01-28T03:47:34.000Z" itemprop="datePublished">2020-01-28</time></a>
</div>

    
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/machine-learning/">machine learning</a> / <a class="article-category-link" href="/categories/machine-learning/learning/">learning</a> / <a class="article-category-link" href="/categories/machine-learning/learning/architecture/">architecture</a>
  </div>


  </div>
  <div class="article-inner">

    <div class="article-entry" itemprop="articleBody">
      
        <p>이글은 Medium( <a href="https://medium.com/@mahendrakariya/dark-knowledge-in-neural-networks-467e5d699181" target="_blank" rel="noopener">https://medium.com/@mahendrakariya/dark-knowledge-in-neural-networks-467e5d699181</a> ) 글의 내용을 학습하면서 정리한 글입니다.</p>
<hr>
<p>Neural Network는 그 목적이 각기 다름에도 불구하고, training과정에서 사용하는 network와 deployment과정에서 사용하는 network가 동일한 네트워크입니다. 이를 언급한 위 글에서는 애벌레와 성충이 되는 과정으로 설명하고 있습니다.</p>
<h4 id="1-Dark-Knowledge-개념"><a href="#1-Dark-Knowledge-개념" class="headerlink" title="1) Dark Knowledge 개념"></a><strong>1) Dark Knowledge 개념</strong></h4><p>이러한 내용을 응용하여 neural network에 대한 model compression을  Bucila,.et al( <a href="https://www.cs.cornell.edu/~caruana/compression.kdd06.pdf" target="_blank" rel="noopener">https://www.cs.cornell.edu/~caruana/compression.kdd06.pdf</a> )이 소개하였고,  Geoffrey Hinton,.et al에 의해서 일반화( <a href="https://arxiv.org/abs/1503.02531" target="_blank" rel="noopener">https://arxiv.org/abs/1503.02531</a> ) 되었습니다.</p>
<p>dark knowledge는 hidden knowledge라고도 하며, 이러한 dark knowledge를 추출하고 사용하는 것을 <b>distillation</b>이라고 합니다.  이를 위 글에서 언급한 내용을 토대로 살펴보면</p>
<p>multi-class classification problem(개, 고양이, 소, 자동차)을 살펴보면 hard-decision, normal softmax 적용후, softened softmax적용후 값의 변화는 아래와 같습니다.</p>
<div class="table-container">
<table>
<thead>
<tr>
<th></th>
<th>Cow</th>
<th>Dog</th>
<th>Cat</th>
<th>Car</th>
</tr>
</thead>
<tbody>
<tr>
<td>hard targets(one-hot encoding of the gold class)</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>normal softmax</td>
<td>10^(-6)</td>
<td>.9</td>
<td>.1</td>
<td>10^(-9)</td>
</tr>
<tr>
<td>softened softmax (<strong>softmax-temperature</strong>)</td>
<td>.05</td>
<td>.3</td>
<td>.2</td>
<td>.005</td>
</tr>
</tbody>
</table>
</div>
<p>hard decision을 적용 할 경우 True로 판정되는 label에만 1이 표기가 되며, normal softmax를 적용하면 False에 해당하는 Cow와 Car는 무시해도 될만큼(negligible) 값이 작다고 할 수 있습니다. 하지만 softened softmax(softmax-temperature) 를 적용할 경우 normal softmax보다 풍부한 정보를 나타낼수 있게 됩니다. 이는 Cat이 Cow로 mis-classifying될 가능성(.2와 .05)이 Cat이 Car로 mis-classifying될 가능성(.2와 .005)보다 크다고 할 수 있습니다.  이렇게 유실될 수 있는 정보를 보다 더 나타내는 것이 가능해 집니다.</p>
<hr>
<h4 id="softmax-temperature"><a href="#softmax-temperature" class="headerlink" title="[softmax- temperature]"></a><strong>[softmax- temperature]</strong></h4><p>Hinton에 의해서 소개된 distribution over the class를 계산하기 위한 방법으로,  training시기에 student-teacher network에 동일한  <strong>temperature parameter</strong> 가 적용됩니다. inference시기에는 <strong>temperature parameter=1</strong>로 설정하여 standard softmax를 사용합니다. 이는 knowledge distillation을 통해 training시 student-teacher에 softened softmax를 사용하여 hidden information이 학습되도록 하고, inference시는 normal softmax를 사용한다는 의미입니다.</p>
<script type="math/tex; mode=display">
p_{i}= -\frac{exp(z_{i}/T)}{\sum_{j}{exp(z_{j}/T)}}\\T~is~the~temperature~parameter\\If~T\rightarrow0,~the~distribution~\rightarrow ~Kronecker~(the~one-hot~target~vector)\\If~T\rightarrow +\infty,~the~distribution~\rightarrow a~uniform~distribution</script><hr>
<h4 id="2-Dark-Knwoledge-student-teacher-Architecture"><a href="#2-Dark-Knwoledge-student-teacher-Architecture" class="headerlink" title="2) Dark Knwoledge(student teacher) Architecture"></a><strong>2) Dark Knwoledge(student teacher) Architecture</strong></h4><p>dark knowledge를 추출하여 사용하는 방식은 다음과 같습니다. Teacher에 해당하는 Lage Model을 train하고, 이 Neural Network로부터 dark knowledge(hidden knowledge)를 추출합니다. 이 dark knowledge기반으로 Student에 해당하는 Small Network를 학습시키는 방식입니다.</p>
<p><img src="/images/machine_learning/dark_knowledge_student_teacher_architecture_concept_v20200128.jpg" alt></p>
<p><sup><a href="#fn_" id="reffn_"></a></sup>: [Dark Knowledge Transfering Architecture Concept]</p>
<p>위 Concept Architecture에서 확인할 수 있듯이 Teacher에서 Final Activation Layer(softmax)이전까지의 <strong>logits</strong>를 추출하고, 여기까지의 output에 softened softmax(<strong>softmax-temperature</strong>)를 적용하고, 이를 student network의 output으로 사용하게 됩니다. 이를 통해 dark knowledge 개념에서 살펴본것 처럼 rich information을 전달할 수 있게 됩니다.</p>
<p>이 그림에서 <strong>New Small Model</strong>이 우리가 학습시키는 Student Network가 됩니다. 이 모델은 먼저 Small Model을 만들어 Teacher Model에서 사용한 학습데이터(x_train, y_train)를 통해 학습을 하고 마진가지로 <strong>logits</strong>를 추출하여, <strong>New Small Model</strong>을 만들게 됩니다. 이 모델에 최종적으로 <strong>학습 데이터(x_train, softened_softmax_probaibilties)</strong>를 학습시키는 과정을 통해 dark knowledge를 tranfering하게 됩니다.</p>
<p>이러한 과정을 통해 이미지 분류를 위해서 통상적으로 사용하는 Convolution Network보다 훨씬 파라미터수가 적은 비교적 단순한 Dense Network를 통해서 이미지 분류 문제를 수행할 수 있게 됩니다. light-weight Model을 통해 Performance에 크게 손실이 없는 결과를 도출할 수 있게 됩니다.</p>
<script data-ad-client="ca-pub-4548072043503266" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- Global site tag (gtag.js) - Google Analytics -->

<script async src="https://www.googletagmanager.com/gtag/js?id=UA-158998069-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'UA-158998069-1');
</script>
      
    </div>

    
      

    

    <footer class="article-footer">
      <a data-url="https://purumir.github.io/2020/01/28/dark-knowledge-machine-learning-architecture/" data-id="ckyyjgaru000iisv00xpvdlir" class="article-share-link">
        <i class="fa fa-share"></i> Share
      </a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/dark-knowledge/">dark knowledge</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/knowledge-distillation/">knowledge distillation</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/learning/">learning</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/machine-learning/">machine learning</a></li></ul>


    </footer>
  </div>
  
</article>



  
    <article id="post-급변의-시기를-겪는-아시아의-4마리용-대만-탐방기" class="article article-type-post" itemscope itemprop="blogPost">

  <header class="article-header">
    
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/01/20/급변의-시기를-겪는-아시아의-4마리용-대만-탐방기/">급변의 시기를 겪는 아시아의 4마리용, 대만 탐방기</a>
    </h1>
  


  </header>

  <div class="article-meta">
    <div class="article-datetime">
  <a href="/2020/01/20/급변의-시기를-겪는-아시아의-4마리용-대만-탐방기/" class="article-date"><time datetime="2020-01-20T01:47:41.000Z" itemprop="datePublished">2020-01-20</time></a>
</div>

    
    

  </div>
  <div class="article-inner">

    <div class="article-entry" itemprop="articleBody">
      
        <script data-ad-client="ca-pub-4548072043503266" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-158998069-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'UA-158998069-1');
</script>


      
    </div>

    
      

    

    <footer class="article-footer">
      <a data-url="https://purumir.github.io/2020/01/20/급변의-시기를-겪는-아시아의-4마리용-대만-탐방기/" data-id="ckyyjgary000misv0etw4rima" class="article-share-link">
        <i class="fa fa-share"></i> Share
      </a>
      
      

    </footer>
  </div>
  
</article>



  
    <article id="post-합성곱-신경망-CNN-을-통한-폐기물-분류" class="article article-type-post" itemscope itemprop="blogPost">

  <header class="article-header">
    
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/01/07/합성곱-신경망-CNN-을-통한-폐기물-분류/">합성곱 신경망(CNN)을 통한 폐기물 분류</a>
    </h1>
  


  </header>

  <div class="article-meta">
    <div class="article-datetime">
  <a href="/2020/01/07/합성곱-신경망-CNN-을-통한-폐기물-분류/" class="article-date"><time datetime="2020-01-07T04:53:31.000Z" itemprop="datePublished">2020-01-07</time></a>
</div>

    
    

  </div>
  <div class="article-inner">

    <div class="article-entry" itemprop="articleBody">
      
        <script data-ad-client="ca-pub-4548072043503266" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-158998069-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'UA-158998069-1');
</script>
      
    </div>

    
      

    

    <footer class="article-footer">
      <a data-url="https://purumir.github.io/2020/01/07/합성곱-신경망-CNN-을-통한-폐기물-분류/" data-id="ckyyjgasa000yisv08z9yndcd" class="article-share-link">
        <i class="fa fa-share"></i> Share
      </a>
      
      

    </footer>
  </div>
  
</article>



  


  <div id="page-nav">
    <nav><ul class="pagination"><li class="disabled"><span class="page-prev"><i class="fa fa-chevron-left"></i> Prev</a></li><li class="active"><span class="page-number">1</span></li><li><a class="page-number" href="/page/2/">2</a></li><li><a class="page-next" rel="next" href="/page/2/">Next <i class="fa fa-chevron-right"></i></a></li></ul></nav>
  </div>



        </div>
        <div class="col-sm-3 col-sm-offset-1 blog-sidebar">
          
  <div class="sidebar-module sidebar-module-inset">
  <h4>About</h4>
  <p> Machine Learning Dreamer<br> Data Engineer <br> Product/Project Manager </p><br>
I am curious about machine learning, business intelligence, sw architect, digital transformation and management.<br>

</div>


  
  <div class="sidebar-module">
    <h4>Categories</h4>
    <ul class="sidebar-module-list"><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/categories/data-analytics/">data analytics</a><span class="sidebar-module-list-count">5</span><ul class="sidebar-module-list-child"><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/categories/data-analytics/ETL/">ETL</a><span class="sidebar-module-list-count">2</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/categories/data-analytics/business-intelligence/">business intelligence</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/categories/data-analytics/spark/">spark</a><span class="sidebar-module-list-count">1</span><ul class="sidebar-module-list-child"><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/categories/data-analytics/spark/timeseries/">timeseries</a><span class="sidebar-module-list-count">1</span></li></ul></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/categories/data-analytics/timeseries/">timeseries</a><span class="sidebar-module-list-count">1</span></li></ul></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/categories/data-anlytics/">data anlytics</a><span class="sidebar-module-list-count">2</span><ul class="sidebar-module-list-child"><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/categories/data-anlytics/usecases/">usecases</a><span class="sidebar-module-list-count">2</span><ul class="sidebar-module-list-child"><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/categories/data-anlytics/usecases/subway-station/">subway station</a><span class="sidebar-module-list-count">2</span></li></ul></li></ul></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/categories/digital-transformation/">digital transformation</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/categories/machine-learning/">machine learning</a><span class="sidebar-module-list-count">7</span><ul class="sidebar-module-list-child"><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/categories/machine-learning/computer-vision/">computer vision</a><span class="sidebar-module-list-count">2</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/categories/machine-learning/data-analytics/">data analytics</a><span class="sidebar-module-list-count">3</span><ul class="sidebar-module-list-child"><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/categories/machine-learning/data-analytics/timeseries/">timeseries</a><span class="sidebar-module-list-count">2</span></li></ul></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/categories/machine-learning/learning/">learning</a><span class="sidebar-module-list-count">1</span><ul class="sidebar-module-list-child"><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/categories/machine-learning/learning/architecture/">architecture</a><span class="sidebar-module-list-count">1</span></li></ul></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/categories/machine-learning/natural-language-processing/">natural language processing</a><span class="sidebar-module-list-count">1</span></li></ul></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/categories/management/">management</a><span class="sidebar-module-list-count">2</span><ul class="sidebar-module-list-child"><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/categories/management/leadership/">leadership</a><span class="sidebar-module-list-count">2</span></li></ul></li></ul>
  </div>



  
  <div class="sidebar-module">
    <h4>Tags</h4>
    <ul class="sidebar-module-list"><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/Apache-NiFi/">Apache NiFi</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/ETL/">ETL</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/StreamSets/">StreamSets</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/airflow/">airflow</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/business-intelligence/">business intelligence</a><span class="sidebar-module-list-count">2</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/chatbot/">chatbot</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/cnn/">cnn</a><span class="sidebar-module-list-count">2</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/computer-vision/">computer vision</a><span class="sidebar-module-list-count">2</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/convolutional-neural-network/">convolutional neural network</a><span class="sidebar-module-list-count">2</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/cs224n/">cs224n</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/dark-knowledge/">dark knowledge</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/data-analytics/">data analytics</a><span class="sidebar-module-list-count">2</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/decisionmakingskills/">decisionmakingskills</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/digital-transformation/">digital transformation</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/elasticsearch/">elasticsearch</a><span class="sidebar-module-list-count">2</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/excel/">excel</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/exponential-smoothing/">exponential smoothing</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/gettinf-off/">gettinf off</a><span class="sidebar-module-list-count">2</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/getting-on/">getting on</a><span class="sidebar-module-list-count">2</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/hdfs/">hdfs</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/hdfssensor/">hdfssensor</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/interpersonalskills/">interpersonalskills</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/istio/">istio</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/kafka/">kafka</a><span class="sidebar-module-list-count">2</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/kibana/">kibana</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/knowledge-distillation/">knowledge distillation</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/kubernetes/">kubernetes</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/leadership/">leadership</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/learning/">learning</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/machine-learning/">machine learning</a><span class="sidebar-module-list-count">8</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/management/">management</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/movement-pattern/">movement pattern</a><span class="sidebar-module-list-count">2</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/moving-average/">moving average</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/ms-power-bi/">ms power bi</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/natural-language-processing/">natural language processing</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/professionalskills/">professionalskills</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/resnet/">resnet</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/spark/">spark</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/sparkstreaming/">sparkstreaming</a><span class="sidebar-module-list-count">2</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/subway-station/">subway station</a><span class="sidebar-module-list-count">2</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/timeseries/">timeseries</a><span class="sidebar-module-list-count">4</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/word2vec/">word2vec</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/workflow/">workflow</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/광역자치단체/">광역자치단체</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/구간평균법/">구간평균법</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/내가준비하고있는리더십/">내가준비하고있는리더십</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/리더십/">리더십</a><span class="sidebar-module-list-count">2</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/명분/">명분</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/세종대왕/">세종대왕</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/승차/">승차</a><span class="sidebar-module-list-count">2</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/시계열/">시계열</a><span class="sidebar-module-list-count">3</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/일별/">일별</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/지수평활법/">지수평활법</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/지하철/">지하철</a><span class="sidebar-module-list-count">2</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/출생아수/">출생아수</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/tags/하차/">하차</a><span class="sidebar-module-list-count">2</span></li></ul>
  </div>



  
  <div class="sidebar-module">
    <h4>Tag Cloud</h4>
    <p class="tagcloud">
      <a href="/tags/Apache-NiFi/" style="font-size: 10px;">Apache NiFi</a> <a href="/tags/ETL/" style="font-size: 10px;">ETL</a> <a href="/tags/StreamSets/" style="font-size: 10px;">StreamSets</a> <a href="/tags/airflow/" style="font-size: 10px;">airflow</a> <a href="/tags/business-intelligence/" style="font-size: 12.5px;">business intelligence</a> <a href="/tags/chatbot/" style="font-size: 10px;">chatbot</a> <a href="/tags/cnn/" style="font-size: 12.5px;">cnn</a> <a href="/tags/computer-vision/" style="font-size: 12.5px;">computer vision</a> <a href="/tags/convolutional-neural-network/" style="font-size: 12.5px;">convolutional neural network</a> <a href="/tags/cs224n/" style="font-size: 10px;">cs224n</a> <a href="/tags/dark-knowledge/" style="font-size: 10px;">dark knowledge</a> <a href="/tags/data-analytics/" style="font-size: 12.5px;">data analytics</a> <a href="/tags/decisionmakingskills/" style="font-size: 10px;">decisionmakingskills</a> <a href="/tags/digital-transformation/" style="font-size: 10px;">digital transformation</a> <a href="/tags/elasticsearch/" style="font-size: 12.5px;">elasticsearch</a> <a href="/tags/excel/" style="font-size: 10px;">excel</a> <a href="/tags/exponential-smoothing/" style="font-size: 10px;">exponential smoothing</a> <a href="/tags/gettinf-off/" style="font-size: 12.5px;">gettinf off</a> <a href="/tags/getting-on/" style="font-size: 12.5px;">getting on</a> <a href="/tags/hdfs/" style="font-size: 10px;">hdfs</a> <a href="/tags/hdfssensor/" style="font-size: 10px;">hdfssensor</a> <a href="/tags/interpersonalskills/" style="font-size: 10px;">interpersonalskills</a> <a href="/tags/istio/" style="font-size: 10px;">istio</a> <a href="/tags/kafka/" style="font-size: 12.5px;">kafka</a> <a href="/tags/kibana/" style="font-size: 10px;">kibana</a> <a href="/tags/knowledge-distillation/" style="font-size: 10px;">knowledge distillation</a> <a href="/tags/kubernetes/" style="font-size: 10px;">kubernetes</a> <a href="/tags/leadership/" style="font-size: 10px;">leadership</a> <a href="/tags/learning/" style="font-size: 10px;">learning</a> <a href="/tags/machine-learning/" style="font-size: 20px;">machine learning</a> <a href="/tags/management/" style="font-size: 10px;">management</a> <a href="/tags/movement-pattern/" style="font-size: 12.5px;">movement pattern</a> <a href="/tags/moving-average/" style="font-size: 10px;">moving average</a> <a href="/tags/ms-power-bi/" style="font-size: 10px;">ms power bi</a> <a href="/tags/natural-language-processing/" style="font-size: 10px;">natural language processing</a> <a href="/tags/professionalskills/" style="font-size: 10px;">professionalskills</a> <a href="/tags/resnet/" style="font-size: 10px;">resnet</a> <a href="/tags/spark/" style="font-size: 10px;">spark</a> <a href="/tags/sparkstreaming/" style="font-size: 12.5px;">sparkstreaming</a> <a href="/tags/subway-station/" style="font-size: 12.5px;">subway station</a> <a href="/tags/timeseries/" style="font-size: 17.5px;">timeseries</a> <a href="/tags/word2vec/" style="font-size: 10px;">word2vec</a> <a href="/tags/workflow/" style="font-size: 10px;">workflow</a> <a href="/tags/광역자치단체/" style="font-size: 10px;">광역자치단체</a> <a href="/tags/구간평균법/" style="font-size: 10px;">구간평균법</a> <a href="/tags/내가준비하고있는리더십/" style="font-size: 10px;">내가준비하고있는리더십</a> <a href="/tags/리더십/" style="font-size: 12.5px;">리더십</a> <a href="/tags/명분/" style="font-size: 10px;">명분</a> <a href="/tags/세종대왕/" style="font-size: 10px;">세종대왕</a> <a href="/tags/승차/" style="font-size: 12.5px;">승차</a> <a href="/tags/시계열/" style="font-size: 15px;">시계열</a> <a href="/tags/일별/" style="font-size: 10px;">일별</a> <a href="/tags/지수평활법/" style="font-size: 10px;">지수평활법</a> <a href="/tags/지하철/" style="font-size: 12.5px;">지하철</a> <a href="/tags/출생아수/" style="font-size: 10px;">출생아수</a> <a href="/tags/하차/" style="font-size: 12.5px;">하차</a>
    </p>
  </div>


  
  <div class="sidebar-module">
    <h4>Archives</h4>
    <ul class="sidebar-module-list"><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2022/01/">1월 2022</a><span class="sidebar-module-list-count">2</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2021/10/">10월 2021</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2021/03/">3월 2021</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2020/05/">5월 2020</a><span class="sidebar-module-list-count">2</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2020/02/">2월 2020</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2020/01/">1월 2020</a><span class="sidebar-module-list-count">3</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2019/12/">12월 2019</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2019/11/">11월 2019</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2019/10/">10월 2019</a><span class="sidebar-module-list-count">7</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2019/09/">9월 2019</a><span class="sidebar-module-list-count">1</span></li></ul>
  </div>



  
  <div class="sidebar-module">
    <h4>Recents</h4>
    <ul class="sidebar-module-list">
      
        <li>
          <a href="/2022/01/23/2021년-서울지하철을-통해-본-사람들의-이동-노선별-일별-요일별-월별-승-하차/">2021년 서울지하철을 통해 본 사람들의 이동-(노선별) 일별 승하차</a>
        </li>
      
        <li>
          <a href="/2022/01/22/2021년-서울지하철을-통해-본-사람들의-이동/">2021년 서울지하철을 통해 본 사람들의 이동- 목표 그리고 데이터셋</a>
        </li>
      
        <li>
          <a href="/2021/10/15/airflow-hdfs-sensor/">airflow hdfs sensor 설정과 사용법</a>
        </li>
      
        <li>
          <a href="/2021/03/30/ResNet/">ResNet</a>
        </li>
      
        <li>
          <a href="/2020/05/21/kubernetes로-spark-submit하기-spark-submit-to-kubernetes/">kubernetes로 spark-submit하기(spark-submit to kubernetes)</a>
        </li>
      
    </ul>
  </div>



        </div>
    </div>
  </div>
  <footer class="blog-footer">
  <div class="container">
    <div id="footer-info" class="inner">
      &copy; 2022 Purumir. This articles are licensed under CC BY-NC 4.0.<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

  

<script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.4/jquery.min.js" integrity="sha384-8gBf6Y4YYq7Jx97PIqmTwLPin4hxIzQw5aDmUg/DDhul9fFpbbLcLh3nTIIDJKhx" crossorigin="anonymous"></script>

<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/js/bootstrap.min.js" integrity="sha384-0mSbJDEHialfmuBBQP6A4Qrprq5OVfW37PRR3j5ELqxss1yVqOtnepnHVP9aJ7xS" crossorigin="anonymous"></script>



<script src="/js/script.js"></script>

</body>
</html>
